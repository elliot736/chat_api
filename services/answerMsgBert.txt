import tensorflow as tf
import numpy as np
from transformers import BertTokenizer
# import model

model = tf.keras.models.load_model('./model')

tokenizer = BertTokenizer.from_pretrained('bert-base-cased')

def prepare_data(input_text, tokenizer):
    token = tokenizer.encode_plus(
        input_text,
        max_length=32, 
        truncation=True, 
        padding='max_length', 
        add_special_tokens=True,
        return_tensors='tf'
    )
    return {
        'input_ids': tf.cast(token.input_ids, tf.float64),
        'attention_mask': tf.cast(token.attention_mask, tf.float64)
    }

def make_prediction(model, processed_data, classes=['printing error', 'login error', 'wifi error', 'monitor error',
       'slow computer']):
    probs = model.predict(processed_data)[0]
    return classes[np.argmax(probs)]


def answerMsgBert(msg):
    processed_data = prepare_data(msg, tokenizer)
    result = make_prediction(model, processed_data=processed_data)
    return result